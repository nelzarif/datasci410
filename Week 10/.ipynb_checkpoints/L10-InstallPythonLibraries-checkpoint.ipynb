{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Python Libraries for Lesson 10\n",
    "\n",
    "Here are some additional libraries you may not have installed previously.\n",
    "1. First verify the library is not pre-installed.\n",
    "2. Then install the library via pip within the container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example with the `arrow` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arrow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-59c3e9d7db5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# try to import a library I knew would be missing to verify it's not pre-installed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0marrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'arrow'"
     ]
    }
   ],
   "source": [
    "# try to import a library I knew would be missing to verify it's not pre-installed\n",
    "import arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arrow\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/39/a8e116084cf4160f0821ca9bb84ec312ccca84caa2b2bffb70d95d47f91f/arrow-0.15.4-py2.py3-none-any.whl (45kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\h189037\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from arrow) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\h189037\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from python-dateutil->arrow) (1.12.0)\n",
      "Installing collected packages: arrow\n",
      "Successfully installed arrow-0.15.4\n"
     ]
    }
   ],
   "source": [
    "# use the bang ! syntax to install the library via pip within the container\n",
    "!pip install arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow  # now the import succeeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple-lda (0.3.0)          - Python library for Latent Dirichlet allocation (lda)\n",
      "lda (1.1.0)                 - Topic modeling with latent Dirichlet allocation\n",
      "LDA-final-mz136 (1.5)       - Latent Dirichlet Allocation\n",
      "LDA-project-19 (1.5)        - Latent Dirichlet Allocation\n",
      "qlda (0.1.8)                - Lda-MLOPE\n",
      "tmlib (0.2.2)               - This is a LDA Package\n",
      "LDA-final-project-19 (1.5)  - Latent Dirichlet Allocation\n",
      "xbob.example.lda (1.0.3)    - (Fisher) Iris Flower LDA example\n",
      "pti-analyzer (0.0.19)       - Analyzing articles based on topic model(LDA)\n",
      "rlda (0.61)                 - A module to use robust lda topics for the study of text\n",
      "easyLDA (0.2.8.6)           - easily bult LDA Topic Models with just a list of docs (e.g. a list of twitter posts in CSV/TXT\n"
     ]
    }
   ],
   "source": [
    "!pip search lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## editdistance Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import editdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nltk Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rake-nltk (1.0.2)              - Python implementation of the Rapid Automatic Keyword Extraction algorithm using NLTK\n",
      "nltk (3.2.5)                   - Natural Language Toolkit\n",
      "  INSTALLED: 3.2.4\n",
      "  LATEST:    3.2.5\n",
      "nltkw (0.1.0)                  - NLTK wrapper\n",
      "nltkrest (0.12)                - NLTK as a REST service\n",
      "nltk_tgrep (1.0.6)             - tgrep2 Searching for NLTK Trees\n",
      "lektor-natural-language (0.1)  - Adds NLTK based template filters.\n",
      "bluestocking (0.1.2)           - An information extraction toolkit built on top of NLTK.\n",
      "luvina (0.0.26)                - High-level API for Natural Language Processing in NLTK\n",
      "wordgrapher (0.3.1)            - Word Graph utility built with NLTK and TextBlob\n",
      "metanl (0.5.6)                 - Multilingual natural language tools, wrapping NLTK and other systems.\n",
      "SloPOS (1.0)                   - Part of speech tagger for Slovenian (SI) language based on NLTK\n",
      "pysummarize (0.6.0)            - Simple multi-language Python and NLTK-based implementation of text summarization\n",
      "namebot (0.1.5)                - A company/product name generating tool written in Python.Uses NLTK and diverse wordplay techniques for sophisticated word generation and ideation\n"
     ]
    }
   ],
   "source": [
    "!pip search nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MessagePack\n",
    "It's like JSON. But fast and small.\n",
    "See <a href=\"https://msgpack.org/index.html\" title=\"MessagePack documentation\">msgpack.org</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install msgpack --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim\n",
    "Gensim is a Python library for topic modeling, document indexing and similarity retrieval with large corpora. Target audience is the natural language processing (NLP) and information retrieval (IR) community.\n",
    "See https://pypi.org/project/gensim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe: Global Vectors for Word Representation\n",
    "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. <a href=\"https://nlp.stanford.edu/pubs/glove.pdf\" title=\"PDF for GloVe\">GloVe: Global Vectors for Word Representation</a>.\n",
    "\n",
    "You may encounter trouble installing this package because of Windows directory naming. See https://github.com/maciejkula/glove-python/issues/42 for more information and help installing. This package is not used in the Lesson 10 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install glove_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stopwords\n",
    "Stopwords filter for 42 languages\n",
    "See https://pypi.org/project/stopwords/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip search stopwords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
